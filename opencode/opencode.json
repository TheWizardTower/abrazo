{
  "$schema": "https://opencode.ai/config.json",
  "permission": {
    "lsp": "allow"
  },
  "provider": {
    "cursor": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Cursor Agent (local)",
      "options": {
        "baseURL": "http://127.0.0.1:32123/v1"
      },
      "models": {
        "auto": {
          "name": "Cursor Agent Auto"
        },
        "gpt-5": {
          "name": "Cursor Agent GPT-5 (alias â†’ gpt-5.2)"
        },
        "gpt-5.2": {
          "name": "Cursor Agent GPT-5.2"
        },
        "gpt-5.1": {
          "name": "Cursor Agent GPT-5.1"
        },
        "gpt-5.1-codex": {
          "name": "Cursor Agent GPT-5.1 Codex"
        },
        "sonnet-4.5": {
          "name": "Cursor Agent Sonnet 4.5"
        },
        "sonnet-4.5-thinking": {
          "name": "Cursor Agent Sonnet 4.5 Thinking"
        },
        "claude-4.5-opus-thinking": {
          "name": "Claude 4.5 Opus Thinking"
        },
        "claude-4.5-opus": {
          "name": "Claude 4.5 Opus"
        }
      }
    },
    "llama.cpp": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "llama-swap",
      "options": {
        "baseURL": "http://192.168.1.140:8080/v1"
      },
      "models": {
        "Qwen3-Next-80B-A3B-Instruct-UD-Q4-K-XL": {
          "name": "Qwen3-Next 80B MoE (3B active) - SWE/coding/reasoning",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          }
        },
        "Qwen3-Next-80B-A3B-Thinking-UD-Q4-K-XL": {
          "name": "Qwen3-Next Thinking - hard reasoning/math/debugging",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          },
          "options": {
            "reasoningEffort": "high"
          }
        },
        "gpt-oss-120b": {
          "name": "GPT-OSS 120B MoE (ROCm) - general reasoning/tool use (slow)",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          }
        },
        "gpt-oss-120b-vulkan": {
          "name": "GPT-OSS 120B MoE (Vulkan) - general reasoning/tool use (slow)",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          }
        },
        "RNJ-1-Instruct": {
          "name": "RNJ-1 Instruct. Small model for the all-famous Ralph Wiggum Loop",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          }
        },
        "Devstral-Small-2505-UD-Q8_K_XL": {
          "name": "Devstral 24B - agentic SWE/multi-file edits",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          }
        },
        "Strand-Rust-Coder-14B": {
          "name": "Strand Rust Coder 14B - Rust specialist",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 32000,
            "output": 32768
          }
        },
        "c4ai-command-a-111B": {
          "name": "Command A 111B - RAG/tool chains/grounded generation (slow)",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 32000,
            "output": 32768
          }
        },
        "Nemotron-3-Nano-30B-A3B": {
          "name": "Nemotron 3 Nano 30B MoE (3B active) - agentic/infra/reasoning",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          },
          "options": {
            "reasoningEffort": "high"
          }
        },
        "Mistral-Small-3.2-24B": {
          "name": "Mistral Small 3.2 24B - infra/DevOps/tool calling",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          }
        },
        "Ministral-3-14B-Instruct": {
          "name": "Ministral 14B - fast lightweight coding/Q&A",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 32000,
            "output": 32768
          }
        },
        "GLM-4.7-Flash-UD-Q8-K_XL": {
          "name": "GLM-4.7 Flash 30B MoE - coding/reasoning/agentic",
          "modalities": {
            "input": [
              "text"
            ],
            "output": [
              "text"
            ]
          },
          "limit": {
            "context": 64000,
            "output": 65536
          }
        }
      }
    }
  },
  "mcp": {
    "serena": {
      "type": "local",
      "command": [
        "serena-mcp-server",
        "--project-from-cwd"
      ],
      "enabled": true
    }
  },
  "plugin": [
    "opencode-cursor-auth@1.0.16",
    "cc-safety-net"
  ]
}
